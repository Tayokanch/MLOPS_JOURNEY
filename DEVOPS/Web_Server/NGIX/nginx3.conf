
# This controls how many parallel processed that Nginx should start with
# Workker Processes are the ones that are actually doing the work of getting and processing the requests coming from the browser or clients
# The number of worker proccess will directly affect how well Nginx can handle high load of request i.e the more the working procceses, the more the request Nginx can handle
# its advisible to set the Worker Processed to the number of CPU cores that is available on the server that Ngix is run
# We can also set is as *auto* where Nginx will decided based on the underline infrastructure

worker_processes 1; 

# This handle the way connection will be hnalded by Nginx, so basically per worker processes

events {
    worker_connections 1024 #This means for 1 worker process that we have, it will handle 1024 simultaneous connections
}

http{

# This inlcudes the file types in the response to the client
include mime.types;

# Define a group of backend servers (upstream) for load balancing
upstream express_backend {
    server container1:3000;   # Backend container 1, port 3000
    server container2:3001;   # Backend container 2, port 3001
    server container3:3002;   # Backend container 3, port 3002
    server container4:3003;   # Backend container 4, port 3003
}
server {
    listen 80;
    server_name example.com;

    location / {
        proxy_pass http://express_backend;  # Forward requests to the upstream backend group

        # Forward the original Host header i.e When Nginx gets request from client, we want Nginx to forward the requested URL to the backend service, so the backend service can see the original request from the client
        proxy_set_header Host $host;  

        
        # Forward the client IP address that made the request
        proxy_set_header X-Real-IP $remote_addr;
        
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;  # Add client IP to the X-Forwarded-For chain
        proxy_set_header X-Forwarded-Proto $scheme;  # Forward the original protocol (HTTP/HTTPS)
    }

}

}